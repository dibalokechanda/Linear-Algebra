---
title: 1.1. Matix Vector Multiplication
draft: false
date: 2023-12-23
---

Consider a matrix $\mathbf{A} \in \mathbb{C}^{m\times n}$ and a vector $\mathbf{x} \in \mathbb{C}^{n}$. 

 $$
\mathbf{A}=\left[\begin{array}{cccc}
\mid & \mid & & \mid \\
\mathbf{a_1} & \mathbf{a_2} & \ldots & \mathbf{a_n} \\
\mid & \mid & & \mid
\end{array}\right]
$$
  
where, $\mathbf{a_1},\mathbf{a_2},\ldots,\mathbf{a_n}$ are columns of matrix $\mathbf{A}$. 

$$

\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}
$$


There are several ways we can interpret the Matrix vector multiplication. 


## Linear Combination of Columns of Matrix

A way to express it is scaling the columns of $\mathbf{A}$ with the elements of vector $\mathbf{x}$. 



$$
\begin{align*}
\mathbf{A}\mathbf{x} & = \left[\begin{array}{cccc}
\mid & \mid & & \mid \\
\mathbf{a_1} & \mathbf{a_2} & \ldots & \mathbf{a_n} \\
\mid & \mid & & \mid
\end{array}\right] \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} \\ \\&= x_1 \mathbf{a_1}+x_2\mathbf{a_2}+ \ldots +x_n\mathbf{a_n}
\end{align*}
$$


This can be written in a much more compact form as follows:

$$
\mathbf{A}\mathbf{x}= x_1 \mathbf{a_1}+x_2\mathbf{a_2}+ \ldots +x_n\mathbf{a_n}= \sum_{i=1}^{n}x_{1} \mathbf{a_1}
$$

This is nothing but a linear combination of the columns of matrix $\mathbf{A}$. 


## Functional Transformation Perspective

We can interpret the matrix-vector multiplication through the lens of functions.

Consider a function $f:\mathbb{R}^{n} \rightarrow \mathbb{R}^m$ and the matrix-vector multiplication can be thought of as the following transformation:

$$
f(\mathbf{x})=\mathbf{A} \mathbf{x}
$$

To put it into words, we are plugging in a vector $\mathbf{x} \in \mathbb{R}^{n}$ which results in applying a transformation defined by a matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$. The result of the transformation is another vector in $\mathbb{R}^{m}$.  This can be further interpreted as a mapping between two vector spaces; from $\mathbb{R}^{n}$ to  $\mathbb{R}^{m}$.

![[Pasted image 20231226003150.png]]

Note that this holds true for $f:\mathbb{C}^{n} \rightarrow \mathbb{C}^m$ also. 

Most of the time we do not separate out the input space and the output space of the function rather superimpose them in a single plot. This allows us to visualize the transformation  in a single plot. 

Now what kind of transformation would it be depends on the nature of the 
matrix. Visualization and intuition behind these transformations are explained in detail in [[1.3. Matrix Multiplication as Transformation|Matrix Multiplication as Transformation]].

Another important thing to mention here, these transformations require one specific property which is the function needs to be linear. In other words, these transformations need to hold the [[1.2. Linearity|Linearity]] property .

### Establishing the relation with elementary basis vector 

Rather than thinking about the matrix $\mathbf{A}$ transforming the vector $\mathbf{x}$, we can think about it from another perspective. To do this we need to decompose the vector $\mathbf{x}$ into elementary basis vectors.

$$
\mathbf{x} = x_1 \mathbf{e_1}+x_2 \mathbf{e_2}+ \cdots+ x_n \mathbf{e_n}
$$

where, $\mathbf{e_1},\mathbf{e_2},\cdots, \mathbf{e_n}$ are the elementary basis vectors.

For better understanding let's write out the expression more explicitly,

$$
\mathbf{x} = x_1 \begin{bmatrix} 1 \\0\\ 0 \\ \vdots \\ 0\end{bmatrix}+ x_2 \begin{bmatrix} 0 \\1\\ 0 \\ \vdots \\ 0\end{bmatrix}+ x_3 \begin{bmatrix} 0 \\0\\ 1 \\ \vdots \\ 0\end{bmatrix}+ \ldots+  x_n \begin{bmatrix} 0 \\0\\ 0 \\ \vdots \\ 1\end{bmatrix}
$$
Visualize this as decomposing the vector $\mathbf{x}$ into it's elementary basis vectors. T

Now, when multiply the matrix with the vector $\mathbf{x}$, what actually get



## Inner Product Perspective

For this perspective we need to express the matrix $\mathbf{A}$ as follows:


$$
\mathbf{A}=\left[\begin{array}{ccc}
- & \mathbf{a_1}^{\top} & - \\

- & \mathbf{a_2}^{\top} & - \\

& \vdots & \\

-& \mathbf{a_n}^{\top} & -
\end{array}\right]
$$

Considering this, the matrix-vector multiplication can be expressed as the following:


$$
\mathbf{A}\mathbf{x} = \left[ \begin{array}{c}\langle \mathbf{a_1},\mathbf{x }\rangle  \\\ \langle \mathbf{a_2},\mathbf{x }\rangle \\ \vdots \\ \langle \mathbf{a_n},\mathbf{x}\rangle\end{array} \right]
$$




## Forming the connection with Basis 
## References 

 1. Gundersen, Gregory. _Matrices as Functions, Matrices as Data_. 28 Aug. 2022, gregorygundersen.com/blog/2022/08/28/matrices-as-functions-and-data/.
 2. Bernstein, Matthew . _Matrix-vector multiplication_. 19 Dec. 2020, mbernste.github.io/posts/matrix_vector_mult.