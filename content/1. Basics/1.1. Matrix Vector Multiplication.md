---
title: 1.1. Matix Vector Multiplication
draft: false
date: 2023-12-23
---

Consider a matrix $\mathbf{A} \in \mathbb{C}^{m\times n}$ and a vector $\mathbf{x} \in \mathbb{C}^{n}$. 

 $$
\mathbf{A}=\left[\begin{array}{cccc}
\mid & \mid & & \mid \\
\mathbf{a_1} & \mathbf{a_2} & \ldots & \mathbf{a_n} \\
\mid & \mid & & \mid
\end{array}\right]
$$
  
where, $\mathbf{a_1},\mathbf{a_2},\ldots,\mathbf{a_n}$ are columns of matrix $\mathbf{A}$. 

$$

\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}
$$


There are several ways we can interpret the Matrix vector multiplication. 


## Linear Combination of Columns of Matrix

A way to express it is scaling the columns of $\mathbf{A}$ with the elements of vector $\mathbf{x}$. 



$$
\begin{align*}
\mathbf{A}\mathbf{x} & = \left[\begin{array}{cccc}
\mid & \mid & & \mid \\
\mathbf{a_1} & \mathbf{a_2} & \ldots & \mathbf{a_n} \\
\mid & \mid & & \mid
\end{array}\right] \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} \\ \\&= x_1 \mathbf{a_1}+x_2\mathbf{a_2}+ \ldots +x_n\mathbf{a_n}
\end{align*}
$$


This can be written in a much more compact form as follows:

$$
\mathbf{A}\mathbf{x}= x_1 \mathbf{a_1}+x_2\mathbf{a_2}+ \ldots +x_n\mathbf{a_n}= \sum_{i=1}^{n}x_{1} \mathbf{a_1}
$$

This is nothing but a linear combination of the columns of matrix $\mathbf{A}$. 


## Functional Transformation Perspective

We can interpret the matrix-vector multiplication through the lens of functions.

Consider a function $f:\mathbb{R}^{n} \rightarrow \mathbb{R}^m$ and the matrix-vector multiplication can be thought of as the following transformation:

$$
f(\mathbf{x})=\mathbf{A} \mathbf{x}
$$

To put it into words, we are plugging in a vector $\mathbf{x} \in \mathbb{R}^{n}$ which results in applying a transformation defined by a matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$. The result of the transformation is another vector in $\mathbb{R}^{m}$.  This can be further interpreted as a mapping between two vector spaces; from $\mathbb{R}^{n}$ to  $\mathbb{R}^{m}$.

![[Pasted image 20231226003150.png]]

Note that this holds true for $f:\mathbb{C}^{n} \rightarrow \mathbb{C}^m$ also. 

Now what kind of transformation would it be depends on the nature of the 
matrix. Visualization and intuition behind these transformations are explained in detail in [[1.3. Matrix Multiplication as Transformation|Matrix Multiplication as Transformation]].

Another important thing to mention here, these transformations require one specific property which is the function needs to be linear. In other words, these transformations need to hold the [[1.2. Linearity|Linearity]] property .


## Inner Product Perspective

For this perspective we need to express the matrix $\mathbf{A}$ as follows:


$$
\mathbf{A}=\left[\begin{array}{ccc}
- & \mathbf{a_1}^{\top} & - \\

- & \mathbf{a_2}^{\top} & - \\

& \vdots & \\

-& \mathbf{a_n}^{\top} & -
\end{array}\right]
$$

Considering this, the matrix-vector multiplication can be expressed as the following:


$$
\mathbf{A}\mathbf{x} = \left[ \begin{array}{c}\langle \mathbf{a_1},\mathbf{x }\rangle  \\\ \langle \mathbf{a_2},\mathbf{x }\rangle \\ \vdots \\ \langle \mathbf{a_n},\mathbf{x}\rangle\end{array} \right]
$$



## References 

 1. Gundersen, Gregory. _Matrices as Functions, Matrices as Data_. 28 Aug. 2022, gregorygundersen.com.
 2. Bernstein, Matthew . _Matrix-vector multiplication_. 19 Dec. 2020, mbernste.github.io/posts/matrix_vector_mult.